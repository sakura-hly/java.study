# 定目标
明确写出性能/稳定性的目标，包括：
1. 接口响应时间
    1. 平均、P90、P99
2. 接口成功率
    1. 最低目标99.9%
3. （可选）数据一致性（例如对账补偿的异常率）

# 业务相关设计
## 业务流程异常处理
在功能交互流程中，需要标明所有异常情况如何处理
* 只在必要的情况下给予用户提示
* 系统内部做好打点/日志等记录 

典型的异常来源：
* 网络错误
* 前端异常请求
* 服务内部逻辑异常
* 上下游依赖异常
* 存储（数据库/缓存） 故障

一些容易忽略的点：
* 流量突增
* 超时阈值（经验值：P99 x 2）
* 重试策略（是否幂等）


## 服务依赖
识别系统边界处各个上下游依赖，给出服务名/接口名等标识信息
* 其它业务服务（交易、广告、直播、搜索、推荐等）
* 基架中台类服务（API网关、笔记/用户中台等）
* 风控/安审接入点
* 离线型任务（数据分析、音视频处理等）
* 外部第三方供应商（如赛事数据提供商、广告品牌方）

对于每个依赖方，要注意是否有多活部署

## 资源依赖
识别系统需要的存储等基础设施，给出集群名/库表名等标识信息
1. MQ
    1. 优先使用RocketMQ和Kafka，禁止使用RabbitMQ
2. MySQL
    1. 是否分库分表、是否有复杂的排序过滤需求
3. RedTao
    1. 简单的双向关系类数据，若无特殊需求，建议用RedTao存储，典型用法：关系的翻页批量查询、判断关系是否存在
4. Redis
    1. 一般只用作缓存，存放有过期时间的数据
    2. 若需要持久化存储，应单独申请集群，并开启备份机制；不能和缓存类数据混合存放
5. RedKV
    1. 适用于数据量巨大（TB级）、不需要高级数据结构（hyperloglog/Bloom Filter等）、写多读少的场景

## 数据量/流量/机器资源预估
典型步骤：
1. 产品需求方给出业务指标预期，例如PV/UV/DAU/转化率等
    1. 历史上有功能类似的产品，可多借鉴
2. 按照功能设计中的数据处理流程和依赖关系，估算每一处接口的访问量
    1. 重点关注峰值流量
    2. 若该接口在多个场景里都有使用，注意多场景同时产生的累计流量
3. 根据存储系统选型，评估每一个存储系统需要的容量
    1. 读/写操作的访问量，尤其是复杂SQL、特殊数据结构、带有事务的操作
    2. 内存/磁盘存储容量
4. 根据以上数据，和上下游各依赖团队一起，给出各自系统所需的机器资源
    1. 现阶段关注CPU和GPU使用量
    2. 注意晚高峰CPU利用率的要求，现有的指导标准：
        1. 混布集群上的服务，要求不低于45%

注意：
* 大流量场景安排压测，除了通过既定水位（如预估流量的150%）以外，还需要测试出给定机器资源能承载的极限流量
* 压测用例和真实情况肯定有出入，因此需要通过初期小规模放量切流，修正对真实访问量和机器资源的预估
* 一般每个需求都要有逐步放量切流的方案，不能的话要说明原因

## 数据库设计
目前大部分业务的数据库选型都是MySQL，需要给出：
* 表结构DDL（字段注释要齐全）
* 建哪些索引
* 预估数据规模，是否需要分表，分表策略
* 是否存在复杂查询（加锁、表join等）

## 缓存设计
给出每一层的缓存设计，大部分业务使用Redis和本地缓存即可，需要关注的点：
1. 缓存是否要预热，预热方案
2. 缓存淘汰和更新策略（例如：过期时间设定、手动清理时机、容量打满时如何处理，数据变动时如何保证缓存/数据库的一致性）
3. 是否有击穿、雪崩、穿透问题
    1. 击穿：热点数据过期
    2. 雪崩：大量数据同时过期
    3. 穿透：数据库里不存在的数据

## 安全设计
识别业务流程中的安全风险，确定风控/安审的接入点
1. 资产损失（实物奖品、虚拟奖品、优惠券、现金红包等超发错发）
2. 数据隐私（笔记/用户的数据被泄漏、被爬取）
3. 合规安全（政府禁止的违规行为）

提供给前端的接口，注意事项：
1. 是否检查签名
    1. 如果是web使用的接口，是否能走客户端bridge获取更强大的验签机制？
    2. 一般涉及到写操作的接口（如：发笔记、发评论、点赞、收藏、关注）强制走bridge
2. 是否检查登录态
    1. 是否允许游客/临时用户？
3. 是否要求风控开启反爬策略

# 线上故障处理
## 监控告警
1. 必需的基础监控告警: cpu、内存、线程池、jvm、rpc等
2. （可选）根据业务相关设计，给出业务关心的指标及其告警规则。以活动类需求为例，常见的业务指标包括：
    1. 任务完成的数量、耗费时长、成功率
    2. 奖励发放的数量、成功率

## 限流/熔断/降级方案
1. 根据流量预估和实际部署的机器资源，为系统中每一处接口定义限流阈值
    1. 压测环节，除了通过既定水位（如预估流量的150%）以外，还需要测试出当前机器资源能承载的极限流量
        1. 注意：压测得到的极限流量不一定反映真实情况，因为压测的参数构造不能完全等同于线上真实流量，机器的实际可承载上限可能会高于压测结果。一般需要通过初期小规模放量切流，修正对极限值的预估。
    2. 能够在线上动态扩容的服务，需要及时更新限流阈值
2. 和需求方握手，对系统中所有依赖完成强弱分级
    1. 弱依赖出现故障时，一般直接熔断即可；若不适合使用中间件默认的熔断策略（滑动时间窗口错误率），则给出新的熔断策略
    2. 强依赖需要提供降级兜底方案；无法兜底的，需要讲明原因
3. 所有限流/熔断/降级的开关配置，需要具备线上动态调整的能力（无需发版）
    1. 现阶段多使用apollo配置中心，后续全面使用RedCloud服务治理平台
4. 所有方案形成文档，作为线上故障处理的操作预案

## 对账/补偿方案
社区业务大部分情况下不会使用强一致的分布式事务框架，多使用异步对账补偿来达到最终一致性
1. （前置准备）业务流程中各处写操作，尽量保存操作记录和状态
    1. 一般持久化到数据库，架构设计允许的话也可以用缓存
2. （实时补偿）各接口尽量实现业务幂等性，便于线上出错时立即重试
3. （延迟补偿）无法重试、或超出最大重试次数的请求，可使用延迟消息，后续消费者启动修复任务
4. （定时对账）通过分钟/小时/天级别的定时任务，识别系统中的异常数据，自动修复或通知人工干预

# 操作流程
## 上线部署SOP
准备上线前的checklist，和QA同学做好信息同步，包括：
1. 多个模块上线的依赖顺序
2. 每个模块要上线的：
    1. 代码分支/镜像版本
    2. apollo配置
    3. AB实验配置
    4. 其它配置后台（如活动类需求的运营管理后台、物料配置等）
3. 数据库/缓存
    1. 是否清理了测试数据
    2. 容量是否扩到位
4. 出现问题后的回滚预案
    1. 回滚的操作顺序
    2. 灰度期间若有数据写入操作，回滚后如何修复脏数据

必须有灰度环节，灰度环节注意观察的内容包括：
1. 机器基础指标（CPU/内存占用率、JVM GC情况等）
2. 业务监控指标（接口QPS、响应时间、成功率等）
3. 实时日志（除warning/error级别外，也要关注info日志是否反映了正常功能）
观察技巧：
1. 灰度和线上各选一台机器进行全方面的监控指标对比，凡是有明显差异的，都是潜在的风险点
2. 开始滚动发布、扩大流量时，不要松懈，分阶段继续检查，可以识别某些只在大流量场景下出现的bug
注意：
1. 发现任何不符合预期的地方，不要有侥幸心理，停下来

## 故障响应SOP
线上问题处理的基本原则：先通告，后处理；先止损，再查因
1. 先通知合作的研发和QA团队，确认下一步具体的操作，再执行
2. 优先按照上线前准备的预案来止损
3. 预案不能覆盖的情况，需要紧急修改代码的，除特殊情况外都要通知QA决定是否测试

每一步操作都需要发出通告，做好信息同步，并记录操作时间点

